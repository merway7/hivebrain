[
  {
    "title": "Nginx reverse proxy to Node.js app with correct headers",
    "category": "pattern",
    "tags": ["nginx", "reverse-proxy", "nodejs", "headers"],
    "problem": "When proxying requests from nginx to a Node.js backend, the app sees 127.0.0.1 as the client IP and incorrect protocol/host headers, breaking features that depend on real client information.",
    "solution": "Set proxy headers explicitly in the nginx location block:\n\n```nginx\nserver {\n    listen 80;\n    server_name example.com;\n\n    location / {\n        proxy_pass http://127.0.0.1:3000;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_cache_bypass $http_upgrade;\n    }\n}\n```\n\nIn Express, trust the proxy:\n```javascript\napp.set('trust proxy', 1);\n// Now req.ip returns the real client IP\n```",
    "why": "Nginx rewrites headers when proxying. Without these headers, the backend cannot determine the real client IP or whether the original request was HTTPS.",
    "gotchas": [
      "proxy_http_version 1.1 is required for WebSocket upgrades to work",
      "'trust proxy' in Express must match your exact proxy chain depth — use a number like 1, not just true, in production",
      "X-Forwarded-For is a comma-separated list if multiple proxies are in the chain"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["nginx", "reverse proxy", "X-Forwarded-For", "trust proxy", "real IP", "proxy headers"],
    "severity": "major",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Certbot SSL renewal: automatic renewal with systemd timer",
    "category": "pattern",
    "tags": ["certbot", "ssl", "tls", "letsencrypt", "systemd"],
    "problem": "Let's Encrypt certificates expire every 90 days. Manual renewal is error-prone and can cause downtime if forgotten.",
    "solution": "Use certbot's built-in systemd timer instead of a cron job:\n\n```bash\n# Check that the timer is active\nsystemctl status certbot.timer\n\n# If not active, enable it\nsystemctl enable --now certbot.timer\n\n# Test renewal without actually renewing\ncertbot renew --dry-run\n\n# If using nginx, add a deploy hook to reload nginx after renewal\necho '#!/bin/bash\nnginx -s reload' > /etc/letsencrypt/renewal-hooks/deploy/reload-nginx.sh\nchmod +x /etc/letsencrypt/renewal-hooks/deploy/reload-nginx.sh\n```\n\nVerify the timer fires twice daily:\n```bash\nsystemctl list-timers | grep certbot\n```",
    "why": "The certbot package on modern Debian/Ubuntu installs a systemd timer by default. Using it is more reliable than custom cron jobs and handles edge cases like renewing multiple domains.",
    "gotchas": [
      "Port 80 must be open for HTTP-01 challenge — firewall rules can silently block renewal",
      "If using --standalone mode, the web server must be stopped during renewal; use --nginx or --apache plugin instead",
      "Wildcard certs require DNS-01 challenge, which needs API access to your DNS provider",
      "Check /var/log/letsencrypt/letsencrypt.log if renewal fails"
    ],
    "language": "javascript",
    "framework": null,
    "environment": ["linux", "ubuntu", "debian"],
    "error_messages": [
      "IMPORTANT NOTES: - The following errors were reported by the server: Domain: example.com Type: connection Detail: Fetching http://example.com/.well-known/acme-challenge/...: Connection refused"
    ],
    "keywords": ["certbot", "letsencrypt", "ssl renewal", "https", "certificate expiry", "systemd timer"],
    "severity": "major",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "DNS propagation: why changes take time and how to check them",
    "category": "gotcha",
    "tags": ["dns", "propagation", "networking", "debugging"],
    "problem": "After changing DNS records, the new values appear immediately in some locations but not others, causing inconsistent behavior that is hard to debug.",
    "solution": "Understand TTL and use tools to check propagation status:\n\n```bash\n# Check what a specific DNS server sees\ndig @8.8.8.8 example.com A        # Google DNS\ndig @1.1.1.1 example.com A        # Cloudflare DNS\ndig @208.67.222.222 example.com A  # OpenDNS\n\n# Check TTL of current record (how long caches hold the old value)\ndig example.com A | grep -A1 'ANSWER SECTION'\n\n# Use https://dnschecker.org or https://whatsmydns.net for global view\n\n# Flush local DNS cache (macOS)\nsudo dscacheutil -flushcache && sudo killall -HUP mDNSResponder\n\n# Flush local DNS cache (Linux with systemd-resolved)\nsudo systemd-resolve --flush-caches\n```",
    "why": "DNS is a distributed caching system. Each resolver caches records for the duration of the TTL. Lowering TTL before a migration (24-48 hours ahead) reduces propagation time for the actual change.",
    "gotchas": [
      "TTL changes themselves take the current TTL duration to propagate — plan ahead",
      "Your ISP's DNS resolver may have a minimum TTL floor, ignoring low TTLs",
      "Clearing your browser cache does not flush the OS DNS cache",
      "Some CDN providers have their own propagation delay on top of DNS"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["DNS", "propagation", "TTL", "dig", "nameserver", "cache flush", "migration"],
    "severity": "moderate",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "CDN cache invalidation: purging stale content after deployments",
    "category": "pattern",
    "tags": ["cdn", "cache", "cloudflare", "deployment", "invalidation"],
    "problem": "After deploying new static assets or content, users continue to receive cached old versions from the CDN for the duration of the cache TTL.",
    "solution": "Use one of these strategies:\n\n**Strategy 1: Content-addressed filenames (best for JS/CSS)**\n```javascript\n// In your build tool (webpack/vite), enable content hashing\n// Output: main.a3f8d2b1.js — filename changes when content changes\n// Cache-Control: public, max-age=31536000, immutable\n```\n\n**Strategy 2: API-based purge after deploy (Cloudflare)**\n```bash\ncurl -X POST \"https://api.cloudflare.com/client/v4/zones/$ZONE_ID/purge_cache\" \\\n     -H \"Authorization: Bearer $CF_API_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     --data '{\"purge_everything\":true}'\n```\n\n**Strategy 3: Cache-Control headers for HTML**\n```nginx\nlocation ~* \\.html$ {\n    add_header Cache-Control \"no-cache, must-revalidate\";\n}\nlocation ~* \\.(js|css|png|jpg|woff2)$ {\n    add_header Cache-Control \"public, max-age=31536000, immutable\";\n}\n```",
    "why": "HTML files should never be cached aggressively since they reference JS/CSS by filename. Fingerprinted assets can be cached forever because a new deploy generates a new filename.",
    "gotchas": [
      "Purge everything is a nuclear option — targeted URL purges are safer for large sites",
      "CDN purge APIs are eventually consistent — it can take seconds to minutes to propagate globally",
      "Service workers cache aggressively and can serve stale content even after CDN purge",
      "Preview deployments and production must use separate cache keys"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["CDN", "cache invalidation", "Cloudflare", "cache-control", "fingerprinting", "purge", "deployment"],
    "severity": "moderate",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Load balancer health checks: what they check and why endpoints matter",
    "category": "pattern",
    "tags": ["load-balancer", "health-check", "availability", "kubernetes"],
    "problem": "A server is technically running but in a degraded state (database disconnected, out of memory, job queue backed up). The load balancer keeps routing traffic to it because the process is alive.",
    "solution": "Implement a real health check endpoint that verifies actual dependencies:\n\n```javascript\n// Express health check endpoint\napp.get('/health', async (req, res) => {\n  const checks = {};\n  let status = 200;\n\n  try {\n    await db.raw('SELECT 1'); // verify database connectivity\n    checks.database = 'ok';\n  } catch (err) {\n    checks.database = 'error';\n    status = 503;\n  }\n\n  try {\n    await redis.ping();\n    checks.redis = 'ok';\n  } catch (err) {\n    checks.redis = 'degraded'; // non-fatal\n  }\n\n  res.status(status).json({\n    status: status === 200 ? 'ok' : 'degraded',\n    checks,\n    uptime: process.uptime(),\n    timestamp: new Date().toISOString()\n  });\n});\n```\n\nNginx upstream health check config:\n```nginx\nupstream backend {\n    server 10.0.0.1:3000;\n    server 10.0.0.2:3000;\n}\n```",
    "why": "A process-alive check only confirms the web server is accepting TCP connections. A deep health check catches application-level failures that affect real users.",
    "gotchas": [
      "Health check endpoints must not require authentication — the load balancer calls them without credentials",
      "Distinguish between liveness (restart me) and readiness (send me traffic) probes in Kubernetes",
      "Health checks themselves can cause load — keep them lightweight and avoid expensive queries",
      "Return 503 (not 500) for health failures — some load balancers only remove servers on 5xx"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["health check", "load balancer", "liveness", "readiness", "503", "kubernetes probe", "availability"],
    "severity": "major",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "WebSocket proxy through nginx: configuration for persistent connections",
    "category": "pattern",
    "tags": ["nginx", "websocket", "proxy", "realtime"],
    "problem": "WebSocket connections through an nginx proxy drop after 60 seconds or fail to upgrade, with clients seeing connection errors or silent disconnections.",
    "solution": "Configure nginx to handle the HTTP upgrade handshake and extend timeouts:\n\n```nginx\nmap $http_upgrade $connection_upgrade {\n    default upgrade;\n    ''      close;\n}\n\nserver {\n    listen 443 ssl;\n    server_name example.com;\n\n    location /ws/ {\n        proxy_pass http://127.0.0.1:3000;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection $connection_upgrade;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n\n        # Prevent nginx from closing idle WebSocket connections\n        proxy_read_timeout 3600s;\n        proxy_send_timeout 3600s;\n    }\n}\n```\n\nAlso send application-level pings to keep the connection alive:\n```javascript\n// Server-side ping every 30 seconds\nsetInterval(() => {\n  wss.clients.forEach(ws => {\n    if (ws.isAlive === false) return ws.terminate();\n    ws.isAlive = false;\n    ws.ping();\n  });\n}, 30000);\n```",
    "why": "HTTP/1.1 WebSocket upgrade requires specific headers to switch protocols. The default nginx read_timeout of 60s kills idle connections.",
    "gotchas": [
      "The map block for $connection_upgrade must be at the http context level, not inside server {}",
      "Some CDNs (Cloudflare free plan) do not support WebSockets — check your plan",
      "Sticky sessions are needed if you have multiple backend instances — WebSocket state is per-connection",
      "Firewalls and NAT gateways may have their own idle timeout that kills long-lived connections"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [
      "WebSocket connection to 'wss://example.com/ws' failed: Error during WebSocket handshake: Unexpected response code: 400"
    ],
    "keywords": ["websocket", "nginx", "proxy upgrade", "connection timeout", "realtime", "wss", "ping pong"],
    "severity": "major",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Gzip/Brotli compression in nginx: serving compressed assets",
    "category": "pattern",
    "tags": ["nginx", "compression", "gzip", "brotli", "performance"],
    "problem": "Static assets and API responses are served uncompressed, wasting bandwidth and slowing page loads, especially on mobile connections.",
    "solution": "Enable gzip (and optionally brotli) in nginx:\n\n```nginx\nhttp {\n    # Gzip settings\n    gzip on;\n    gzip_vary on;\n    gzip_proxied any;\n    gzip_comp_level 6;  # 1-9, 6 is a good balance\n    gzip_min_length 256;\n    gzip_types\n        text/plain\n        text/css\n        text/javascript\n        application/json\n        application/javascript\n        application/x-javascript\n        image/svg+xml\n        font/woff2;\n\n    # Brotli (requires ngx_brotli module)\n    # brotli on;\n    # brotli_comp_level 6;\n    # brotli_types text/plain text/css application/json application/javascript;\n\n    server {\n        # Serve pre-compressed files if they exist (.gz or .br)\n        gzip_static on;\n    }\n}\n```\n\nPre-compress assets at build time for best performance:\n```bash\nfind ./dist -type f \\( -name '*.js' -o -name '*.css' \\) \\\n    -exec gzip -9 -k {} \\;\n```",
    "why": "On-the-fly compression adds CPU overhead. Pre-compressing assets during builds serves the best compression with zero runtime cost.",
    "gotchas": [
      "Do not compress already-compressed formats: JPEG, PNG, WebP, WOFF2, MP4 — sizes increase",
      "gzip_vary on adds a Vary: Accept-Encoding header, which is required for correct caching behavior",
      "Brotli requires a separately compiled nginx module — not available in the standard package",
      "comp_level 9 gives diminishing returns; level 6 compresses ~98% as well at significantly less CPU"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["gzip", "brotli", "compression", "nginx", "performance", "bandwidth", "static assets"],
    "severity": "tip",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Log rotation with logrotate: prevent disk fill from application logs",
    "category": "pattern",
    "tags": ["logrotate", "logging", "linux", "operations", "disk"],
    "problem": "Application log files grow indefinitely and eventually fill the disk, causing the application to crash or behave incorrectly.",
    "solution": "Create a logrotate config for your application:\n\n```bash\n# /etc/logrotate.d/myapp\n/var/log/myapp/*.log {\n    daily\n    rotate 14\n    compress\n    delaycompress\n    missingok\n    notifempty\n    sharedscripts\n    postrotate\n        # Tell the app to reopen log files\n        systemctl reload myapp 2>/dev/null || true\n        # Or if using pm2:\n        # pm2 reloadLogs\n    endscript\n}\n```\n\nTest without executing:\n```bash\nlogrotate -d /etc/logrotate.d/myapp\n\n# Force rotation now\nlogrotate -f /etc/logrotate.d/myapp\n\n# Check last run status\ncat /var/lib/logrotate/status | grep myapp\n```",
    "why": "delaycompress keeps the previous log uncompressed for one cycle so that log shippers (like filebeat) can finish reading before compression. postrotate ensures the app opens new file descriptors pointing to the new file.",
    "gotchas": [
      "Without postrotate reload, the app continues writing to the rotated file (old inode), not the new empty one",
      "compress + delaycompress is the correct pairing — compress alone compresses the file the app might still be writing to",
      "logrotate runs daily via /etc/cron.daily — verify cron is running if rotation never happens",
      "For pm2, use pm2 install pm2-logrotate module instead for tighter integration"
    ],
    "language": "javascript",
    "framework": null,
    "environment": ["linux"],
    "error_messages": [
      "No space left on device"
    ],
    "keywords": ["logrotate", "log rotation", "disk full", "log management", "compress", "postrotate"],
    "severity": "major",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Systemd service file for a Node.js application",
    "category": "pattern",
    "tags": ["systemd", "nodejs", "linux", "service", "process-management"],
    "problem": "A Node.js application needs to start automatically on boot, restart on crash, and run under a specific user without root privileges.",
    "solution": "Create a systemd unit file:\n\n```ini\n# /etc/systemd/system/myapp.service\n[Unit]\nDescription=My Node.js Application\nAfter=network.target\n\n[Service]\nType=simple\nUser=deploy\nWorkingDirectory=/opt/myapp\nExecStart=/usr/bin/node /opt/myapp/dist/server.js\nRestart=on-failure\nRestartSec=10\nStandardOutput=journal\nStandardError=journal\nSyslogIdentifier=myapp\n\n# Environment\nEnvironment=NODE_ENV=production\nEnvironmentFile=/opt/myapp/.env\n\n# Security hardening\nNoNewPrivileges=true\nPrivateTmp=true\n\n[Install]\nWantedBy=multi-user.target\n```\n\n```bash\n# Install and start\nsystemctl daemon-reload\nsystemctl enable --now myapp\n\n# Check status and logs\nsystemctl status myapp\njournalctl -u myapp -f\n```",
    "why": "systemd handles process supervision, log collection, dependency ordering, and privilege separation in a single unit file without additional tools.",
    "gotchas": [
      "After=network.target does not wait for network to be fully configured — use After=network-online.target and Wants=network-online.target for apps that need actual connectivity at start",
      "EnvironmentFile path is relative to the filesystem root, not WorkingDirectory",
      "Restart=always restarts even on clean exit (exit code 0) — usually you want Restart=on-failure",
      "Use 'journalctl -u myapp --since today' to limit log output"
    ],
    "language": "javascript",
    "framework": null,
    "environment": ["linux", "ubuntu", "debian"],
    "error_messages": [],
    "keywords": ["systemd", "service file", "nodejs", "process management", "auto-start", "crash restart", "journalctl"],
    "severity": "moderate",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "PM2 process management: ecosystem config and zero-downtime reload",
    "category": "pattern",
    "tags": ["pm2", "nodejs", "process-management", "deployment"],
    "problem": "Running node server.js directly means the process dies on crash, doesn't restart on server reboot, and restarts cause brief downtime.",
    "solution": "Use pm2 with an ecosystem config file:\n\n```javascript\n// ecosystem.config.js\nmodule.exports = {\n  apps: [{\n    name: 'myapp',\n    script: './dist/server.js',\n    instances: 'max',       // Use all CPU cores\n    exec_mode: 'cluster',   // Required for multiple instances\n    watch: false,\n    max_memory_restart: '1G',\n    env: {\n      NODE_ENV: 'development',\n    },\n    env_production: {\n      NODE_ENV: 'production',\n      PORT: 3000,\n    },\n    error_file: '/var/log/myapp/error.log',\n    out_file: '/var/log/myapp/out.log',\n    log_date_format: 'YYYY-MM-DD HH:mm:ss',\n  }]\n};\n```\n\n```bash\n# Start / reload\npm2 start ecosystem.config.js --env production\npm2 reload myapp          # Zero-downtime reload\npm2 save                  # Save process list\npm2 startup               # Generate startup script\n```",
    "why": "Cluster mode distributes connections across worker processes. pm2 reload performs rolling restarts — one worker at a time — so there is no downtime during deploys.",
    "gotchas": [
      "cluster mode requires your app to be stateless — in-memory sessions or WebSocket state breaks with multiple workers",
      "pm2 save must be run after any config change to persist across reboots",
      "pm2 startup generates a command you must run as root — read its output carefully",
      "pm2 logs buffers output — use pm2 flush periodically to prevent the log buffer from growing too large"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["pm2", "cluster mode", "zero downtime", "reload", "ecosystem config", "process manager", "nodejs"],
    "severity": "moderate",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Cron job patterns: syntax, common mistakes, and reliable execution",
    "category": "pattern",
    "tags": ["cron", "scheduling", "linux", "operations"],
    "problem": "Cron jobs fail silently, run with a different environment than expected, or have scheduling syntax errors that are hard to debug.",
    "solution": "Follow these patterns for reliable cron jobs:\n\n```bash\n# Edit crontab for current user\ncrontab -e\n\n# Format: minute hour day month weekday command\n# Run at 2:30 AM every day\n30 2 * * * /opt/myapp/scripts/backup.sh >> /var/log/backup.log 2>&1\n\n# Run every 5 minutes\n*/5 * * * * /opt/myapp/scripts/health-check.sh\n\n# Run on weekdays at 9 AM\n0 9 * * 1-5 /opt/myapp/scripts/report.sh\n```\n\nMake scripts self-sufficient:\n```bash\n#!/bin/bash\n# Always use absolute paths — cron has a minimal PATH\n/usr/bin/node /opt/myapp/scripts/cleanup.js\n\n# Source environment if needed\nset -a\nsource /opt/myapp/.env\nset +a\n```\n\nVerify cron is running and check logs:\n```bash\nsystemctl status cron\ngrep CRON /var/log/syslog | tail -20\n```",
    "why": "Cron runs with a minimal environment (PATH=/usr/bin:/bin). Scripts that work interactively fail in cron because they rely on a full shell environment.",
    "gotchas": [
      "Percent signs (%) in cron commands are interpreted as newlines — escape them as \\%",
      "The cron daemon must be running — check with systemctl status cron (or crond on RHEL)",
      "Use https://crontab.guru to verify your cron expression before deploying",
      "Redirect both stdout and stderr: command >> /log 2>&1 — otherwise errors go to local mail and are invisible"
    ],
    "language": "javascript",
    "framework": null,
    "environment": ["linux"],
    "error_messages": [],
    "keywords": ["cron", "crontab", "scheduling", "PATH", "environment", "silent failure", "automation"],
    "severity": "moderate",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Zero-downtime deployments with rolling restarts and health checks",
    "category": "pattern",
    "tags": ["deployment", "zero-downtime", "rolling-restart", "health-check"],
    "problem": "Deploying new code requires restarting the server, causing a window where requests fail or get dropped.",
    "solution": "Implement a deploy script that validates before switching:\n\n```bash\n#!/bin/bash\nset -e  # Exit on any error\n\nAPP_DIR=/opt/myapp\nNEW_DIR=/opt/myapp-new\n\n# 1. Pull and build new version in separate directory\ngit clone $REPO $NEW_DIR\ncd $NEW_DIR && npm ci && npm run build\n\n# 2. Validate the build starts correctly\nNODE_ENV=production timeout 10 node $NEW_DIR/dist/server.js --check 2>&1 | grep 'OK'\n\n# 3. Copy new files and reload (pm2 cluster reload is atomic)\ncp -r $NEW_DIR/dist $APP_DIR/\npm2 reload myapp\n\n# 4. Wait and verify health\nsleep 5\ncurl -f http://localhost:3000/health || (pm2 reload myapp --revert && exit 1)\n\n# 5. Cleanup\nrm -rf $NEW_DIR\necho 'Deploy complete'\n```",
    "why": "pm2 reload in cluster mode sends SIGINT to one worker, waits for it to finish serving requests, starts a new worker, then proceeds to the next — achieving zero-downtime rolling restart.",
    "gotchas": [
      "SIGINT must be handled gracefully in the app — close database connections and finish in-flight requests",
      "If using sticky sessions, a rolling restart can break existing sessions on that worker",
      "Database migrations must be backward compatible — run them before deploying new code",
      "Have a rollback plan tested before production deploy — not just after something goes wrong"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["zero downtime", "rolling restart", "deployment", "pm2", "graceful shutdown", "health check", "rollback"],
    "severity": "major",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Monitoring basics: what to instrument and alert on",
    "category": "principle",
    "tags": ["monitoring", "observability", "alerting", "operations"],
    "problem": "Applications go down or degrade and nobody notices until users complain. Or alerts fire constantly on noise, training teams to ignore them.",
    "solution": "Instrument the four golden signals:\n\n```javascript\n// 1. Latency — track p50, p95, p99 response times\nconst responseTime = require('response-time');\napp.use(responseTime((req, res, time) => {\n  metrics.histogram('http.response_time_ms', time, {\n    method: req.method,\n    route: req.route?.path || 'unknown',\n    status: res.statusCode\n  });\n}));\n\n// 2. Error rate — 5xx as percentage of all requests\n// 3. Traffic — requests per second\n// 4. Saturation — CPU, memory, DB connection pool usage\n\n// Alert thresholds (start conservative)\n// - Error rate > 1% for 5 minutes\n// - p99 latency > 2s for 5 minutes\n// - Disk usage > 80%\n// - Memory usage > 90% for 10 minutes\n```\n\nMinimal monitoring stack:\n- Metrics: Prometheus + Grafana (self-hosted) or Datadog\n- Uptime: UptimeRobot (free tier covers basics)\n- Errors: Sentry\n- Logs: Loki or CloudWatch",
    "why": "The four golden signals (latency, errors, traffic, saturation) give the most signal about system health with the least noise. Alert on symptoms, not causes.",
    "gotchas": [
      "Alert on user-visible symptoms (error rate, latency) not internal metrics (CPU) — CPU high is not always a problem",
      "Paging alerts should be actionable and require immediate response — otherwise use ticket/email",
      "Track your SLI and SLO — know what 'up' means before an incident, not during one",
      "Keep dashboards simple — a dashboard with 50 panels is useless during an incident"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["monitoring", "golden signals", "alerting", "SLO", "latency", "error rate", "observability", "Prometheus"],
    "severity": "major",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Backup strategies: 3-2-1 rule and automated verification",
    "category": "principle",
    "tags": ["backup", "disaster-recovery", "database", "operations"],
    "problem": "Backups exist but have never been tested. When data loss occurs, the restore process fails or restores corrupt data.",
    "solution": "Follow the 3-2-1 rule and automate restoration testing:\n\n```bash\n#!/bin/bash\n# Automated Postgres backup with verification\nDATE=$(date +%Y%m%d_%H%M%S)\nBACKUP_FILE=\"/backups/db_$DATE.sql.gz\"\n\n# Create backup\npg_dump $DATABASE_URL | gzip > $BACKUP_FILE\n\n# Verify backup is readable and non-empty\nif [ ! -s $BACKUP_FILE ]; then\n    echo \"BACKUP FAILED: empty file\" >&2\n    exit 1\nfi\n\nGZ_TEST=$(gzip -t $BACKUP_FILE 2>&1)\nif [ $? -ne 0 ]; then\n    echo \"BACKUP FAILED: corrupt gzip: $GZ_TEST\" >&2\n    exit 1\nfi\n\n# Upload to offsite storage (S3)\naws s3 cp $BACKUP_FILE s3://$BACKUP_BUCKET/db/\n\n# Delete local backups older than 7 days\nfind /backups -name 'db_*.sql.gz' -mtime +7 -delete\n\necho \"Backup complete: $BACKUP_FILE\"\n```\n\n3-2-1 rule:\n- 3 copies of data\n- 2 different storage media/services\n- 1 offsite copy",
    "why": "An untested backup is not a backup. Backups that fail silently (empty files, corrupt archives) are worse than no backup because they create false confidence.",
    "gotchas": [
      "Test restores quarterly — create a staging environment, restore from backup, verify data integrity",
      "Encrypt backups before uploading to cloud storage — even private S3 buckets can be misconfigured",
      "pg_dump is not crash-consistent for very large databases — consider WAL archiving with pg_basebackup for large datasets",
      "Retention policy is part of the backup strategy — know how far back you can restore"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["backup", "3-2-1 rule", "disaster recovery", "pg_dump", "restoration testing", "offsite", "S3"],
    "severity": "critical",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Nginx static file serving: optimal configuration for SPAs and assets",
    "category": "pattern",
    "tags": ["nginx", "static-files", "spa", "performance", "caching"],
    "problem": "Static file serving is slow or returns 404 for client-side routes in a single-page application because nginx does not know about client-side routing.",
    "solution": "Configure nginx for SPAs with proper cache headers:\n\n```nginx\nserver {\n    listen 443 ssl http2;\n    server_name example.com;\n    root /var/www/myapp/dist;\n    index index.html;\n\n    # Cache fingerprinted assets forever\n    location ~* \\.(js|css|png|jpg|gif|ico|woff2|svg)$ {\n        expires max;\n        add_header Cache-Control \"public, max-age=31536000, immutable\";\n        access_log off;\n    }\n\n    # Never cache HTML\n    location ~* \\.html$ {\n        expires -1;\n        add_header Cache-Control \"no-cache, no-store, must-revalidate\";\n    }\n\n    # SPA fallback — serve index.html for unknown routes\n    location / {\n        try_files $uri $uri/ /index.html;\n    }\n\n    # API proxy\n    location /api/ {\n        proxy_pass http://127.0.0.1:3000;\n    }\n}\n```",
    "why": "try_files $uri $uri/ /index.html is the key for SPAs — it serves the file if it exists, then falls back to index.html so the client-side router takes over.",
    "gotchas": [
      "Without the try_files fallback, refreshing any route other than / returns 404",
      "The order of location blocks matters — more specific patterns (regex) take priority",
      "http2 requires SSL — it cannot run on plain HTTP",
      "access_log off for assets reduces I/O on high-traffic sites significantly"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [
      "404 Not Found"
    ],
    "keywords": ["nginx", "SPA", "try_files", "single page app", "static serving", "cache-control", "client-side routing"],
    "severity": "moderate",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Retry with exponential backoff and jitter for transient failures",
    "category": "pattern",
    "tags": ["retry", "exponential-backoff", "jitter", "resilience", "network"],
    "problem": "A service calls an external API that occasionally returns 429 or 503. Retrying immediately causes a thundering herd that worsens the outage.",
    "solution": "Implement exponential backoff with jitter:\n\n```javascript\nasync function withRetry(fn, options = {}) {\n  const {\n    maxAttempts = 3,\n    baseDelayMs = 100,\n    maxDelayMs = 30000,\n    retryOn = (err) => err.status >= 500 || err.status === 429,\n  } = options;\n\n  let lastError;\n  for (let attempt = 0; attempt < maxAttempts; attempt++) {\n    try {\n      return await fn();\n    } catch (err) {\n      lastError = err;\n      if (attempt === maxAttempts - 1 || !retryOn(err)) throw err;\n\n      // Exponential backoff with full jitter\n      const expDelay = Math.min(baseDelayMs * 2 ** attempt, maxDelayMs);\n      const jitter = Math.random() * expDelay;\n      const delay = Math.floor(jitter);\n\n      console.log(`Attempt ${attempt + 1} failed, retrying in ${delay}ms`, { error: err.message });\n      await new Promise(resolve => setTimeout(resolve, delay));\n    }\n  }\n  throw lastError;\n}\n\n// Usage\nconst result = await withRetry(\n  () => fetch('https://api.example.com/data').then(r => r.json()),\n  { maxAttempts: 4, baseDelayMs: 200 }\n);\n```",
    "why": "Full jitter (random delay between 0 and the exponential cap) spreads retries across time, preventing all clients from retrying in sync which would recreate the spike.",
    "gotchas": [
      "Only retry idempotent operations — retrying a POST that creates a record will create duplicates",
      "Respect Retry-After header from 429 responses instead of calculating your own delay",
      "Set a total timeout budget, not just per-attempt — don't retry indefinitely",
      "Log retry attempts with context so you can detect when retries are masking a real outage"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [
      "Error: 429 Too Many Requests",
      "Error: 503 Service Unavailable"
    ],
    "keywords": ["retry", "exponential backoff", "jitter", "thundering herd", "rate limit", "resilience", "transient error"],
    "severity": "major",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Circuit breaker pattern: fail fast when dependencies are down",
    "category": "pattern",
    "tags": ["circuit-breaker", "resilience", "fault-tolerance", "distributed-systems"],
    "problem": "When a downstream service is down, every request to your service waits for timeout before failing, exhausting your thread pool or connection pool and taking down your service too.",
    "solution": "Implement a circuit breaker with three states:\n\n```javascript\nclass CircuitBreaker {\n  constructor(options = {}) {\n    this.failureThreshold = options.failureThreshold || 5;\n    this.successThreshold = options.successThreshold || 2;\n    this.timeout = options.timeout || 60000; // ms to wait before half-open\n    this.state = 'CLOSED'; // CLOSED, OPEN, HALF_OPEN\n    this.failureCount = 0;\n    this.successCount = 0;\n    this.nextAttempt = Date.now();\n  }\n\n  async call(fn) {\n    if (this.state === 'OPEN') {\n      if (Date.now() < this.nextAttempt) {\n        throw new Error('Circuit breaker is OPEN — call rejected');\n      }\n      this.state = 'HALF_OPEN';\n    }\n\n    try {\n      const result = await fn();\n      this.onSuccess();\n      return result;\n    } catch (err) {\n      this.onFailure();\n      throw err;\n    }\n  }\n\n  onSuccess() {\n    this.failureCount = 0;\n    if (this.state === 'HALF_OPEN') {\n      this.successCount++;\n      if (this.successCount >= this.successThreshold) {\n        this.state = 'CLOSED';\n        this.successCount = 0;\n      }\n    }\n  }\n\n  onFailure() {\n    this.failureCount++;\n    this.successCount = 0;\n    if (this.failureCount >= this.failureThreshold || this.state === 'HALF_OPEN') {\n      this.state = 'OPEN';\n      this.nextAttempt = Date.now() + this.timeout;\n    }\n  }\n}\n\nconst paymentBreaker = new CircuitBreaker({ failureThreshold: 3, timeout: 30000 });\n\n// Usage\ntry {\n  const result = await paymentBreaker.call(() => paymentService.charge(amount));\n} catch (err) {\n  if (err.message.includes('Circuit breaker')) {\n    return { error: 'Payment service temporarily unavailable' };\n  }\n  throw err;\n}\n```",
    "why": "OPEN state rejects calls immediately (fail fast) instead of waiting for timeout. HALF_OPEN state probes the downstream service to see if it has recovered.",
    "gotchas": [
      "Circuit breakers should be per downstream service and per client instance — don't share state across requests",
      "Expose circuit breaker state in your health check endpoint so load balancers can detect cascading failures",
      "The timeout (how long to stay OPEN) needs tuning — too short means probing a still-broken service, too long means unnecessary downtime",
      "Consider using a library like opossum for production use — it handles edge cases you will miss"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [
      "Error: Circuit breaker is OPEN — call rejected"
    ],
    "keywords": ["circuit breaker", "fail fast", "resilience", "cascading failure", "OPEN CLOSED HALF_OPEN", "fault tolerance"],
    "severity": "major",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Store money as integers (cents), never as floats",
    "category": "principle",
    "tags": ["money", "floating-point", "precision", "finance"],
    "problem": "Storing currency amounts as floating-point numbers causes rounding errors that accumulate and produce incorrect totals in financial calculations.",
    "solution": "Always store and compute money as integers in the smallest currency unit:\n\n```javascript\n// WRONG — floating point errors\nconst price = 19.99;\nconst tax = price * 0.08;\nconsole.log(price + tax); // 21.5892 — not what you want\n\n// CORRECT — integer cents\nconst priceCents = 1999;  // $19.99\nconst taxCents = Math.round(priceCents * 0.08); // 160 cents = $1.60\nconst totalCents = priceCents + taxCents; // 2159 cents = $21.59\n\n// Display only\nconst display = (cents) => `$${(cents / 100).toFixed(2)}`;\nconsole.log(display(totalCents)); // '$21.59'\n\n// Database schema\n// amount INTEGER NOT NULL  -- always in cents\n// currency CHAR(3) NOT NULL DEFAULT 'USD'\n\n// Parsing user input\nconst parseAmount = (str) => Math.round(parseFloat(str) * 100);\n```\n\nFor complex calculations use a library:\n```javascript\nimport Dinero from 'dinero.js';\nconst price = Dinero({ amount: 1999, currency: 'USD' });\nconst tax = price.multiply(0.08);\nconsole.log(price.add(tax).toFormat('$0.00'));\n```",
    "why": "IEEE 754 floating-point cannot represent 0.1 exactly. 0.1 + 0.2 === 0.30000000000000004 in JavaScript. Integer arithmetic is exact.",
    "gotchas": [
      "Be careful when converting: 19.99 * 100 = 1998.9999999999998 — always use Math.round() when converting float to cents",
      "Different currencies have different subunits: JPY has no cents, KWD has 3 decimal places",
      "When dividing (splitting a bill), decide on your rounding strategy and document it",
      "Stripe, PayPal, and most payment APIs already expect amounts in the smallest currency unit"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["money", "cents", "integer", "floating point", "currency", "precision", "rounding error", "Dinero"],
    "severity": "critical",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "UUID v7 vs v4: prefer v7 for database primary keys",
    "category": "principle",
    "tags": ["uuid", "database", "primary-key", "performance", "indexing"],
    "problem": "Using UUID v4 (random) as a database primary key causes index fragmentation and poor insert performance at scale because values are not monotonically increasing.",
    "solution": "Use UUID v7 for database primary keys:\n\n```javascript\nimport { v7 as uuidv7, v4 as uuidv4 } from 'uuid';\n\n// UUID v4 — completely random, bad for B-tree indexes\n// Each insert goes to a random position in the index tree\n\n// UUID v7 — time-ordered, good for B-tree indexes\n// Always inserts at the end of the index\nconsole.log(uuidv7()); // '018e74d2-9f9a-7000-8000-4d5f2a3b1c0e'\n\n// UUID v7 is also sortable chronologically\nconst ids = [uuidv7(), uuidv7(), uuidv7()];\nconsole.log(ids.sort()); // already in creation order\n\n// Practical: use ULID as an alternative if v7 isn't available\nimport { ulid } from 'ulid';\nconsole.log(ulid()); // '01ARZ3NDEKTSV4RRFFQ69G5FAV'\n```",
    "why": "B-tree indexes work best with monotonically increasing values. Random UUIDs (v4) cause page splits and fragmentation. UUID v7 encodes a millisecond timestamp in the high bits, so new IDs always append to the end of the index.",
    "gotchas": [
      "UUID v7 exposes creation time — this can be a privacy concern in public-facing APIs",
      "Not all database drivers and ORMs support UUID v7 natively yet",
      "ULID is a popular alternative: 128 bits, sortable, case-insensitive, URL-safe",
      "If you have an existing table with v4 UUIDs, migrating is expensive — evaluate carefully"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["UUID v7", "UUID v4", "primary key", "ULID", "index fragmentation", "B-tree", "sortable ID"],
    "severity": "moderate",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Idempotency keys: safely retrying non-idempotent operations",
    "category": "pattern",
    "tags": ["idempotency", "api", "payments", "distributed-systems", "retry"],
    "problem": "A payment request times out. Was it processed or not? Retrying the same request risks charging the customer twice.",
    "solution": "Generate and store idempotency keys with operations:\n\n```javascript\n// Client: generate a stable key for each logical operation\nconst idempotencyKey = `pay_${orderId}_${userId}`;\n\n// Send with request\nconst response = await fetch('/api/payments', {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json',\n    'Idempotency-Key': idempotencyKey,\n  },\n  body: JSON.stringify({ amount: 1999, currency: 'USD' }),\n});\n\n// Server: check key before processing\napp.post('/api/payments', async (req, res) => {\n  const key = req.headers['idempotency-key'];\n  if (!key) return res.status(400).json({ error: 'Idempotency-Key header required' });\n\n  // Check if this key was already processed\n  const existing = await db.query(\n    'SELECT response FROM idempotency_keys WHERE key = $1 AND expires_at > NOW()',\n    [key]\n  );\n  if (existing.rows[0]) {\n    return res.status(200).json(existing.rows[0].response); // Return cached result\n  }\n\n  // Process payment\n  const result = await processPayment(req.body);\n\n  // Store result with TTL\n  await db.query(\n    \"INSERT INTO idempotency_keys (key, response, expires_at) VALUES ($1, $2, NOW() + INTERVAL '24 hours')\",\n    [key, result]\n  );\n\n  res.status(200).json(result);\n});\n```",
    "why": "Idempotency keys make non-idempotent operations safe to retry by caching the result of the first successful execution and returning it on subsequent requests with the same key.",
    "gotchas": [
      "The idempotency key must be stored atomically with the operation — use a transaction",
      "If two requests with the same key arrive simultaneously, use a database lock or unique constraint to prevent both from proceeding",
      "Expire keys after a reasonable TTL (24 hours to 30 days) to prevent unbounded storage growth",
      "The Stripe API uses Idempotency-Key as the header name — standardize on this"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["idempotency", "idempotency key", "double charge", "safe retry", "payment", "distributed systems"],
    "severity": "critical",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Cursor vs offset pagination: use cursors for large datasets",
    "category": "pattern",
    "tags": ["pagination", "cursor", "offset", "database", "performance"],
    "problem": "OFFSET-based pagination becomes slow on large tables and returns inconsistent results when rows are inserted or deleted between page requests.",
    "solution": "Use cursor-based pagination for large or frequently changing datasets:\n\n```javascript\n// OFFSET — simple but breaks on large offsets and concurrent writes\n// SELECT * FROM posts ORDER BY created_at DESC LIMIT 20 OFFSET 1000000\n// This reads and discards 1 million rows before returning results\n\n// CURSOR — efficient and consistent\napp.get('/api/posts', async (req, res) => {\n  const limit = parseInt(req.query.limit) || 20;\n  const cursor = req.query.cursor; // base64-encoded last seen ID + timestamp\n\n  let query, params;\n  if (cursor) {\n    const { id, createdAt } = JSON.parse(Buffer.from(cursor, 'base64').toString());\n    query = `\n      SELECT id, title, created_at\n      FROM posts\n      WHERE (created_at, id) < ($1, $2)\n      ORDER BY created_at DESC, id DESC\n      LIMIT $3\n    `;\n    params = [createdAt, id, limit + 1];\n  } else {\n    query = `SELECT id, title, created_at FROM posts ORDER BY created_at DESC, id DESC LIMIT $1`;\n    params = [limit + 1];\n  }\n\n  const rows = await db.query(query, params);\n  const hasMore = rows.length > limit;\n  const items = hasMore ? rows.slice(0, limit) : rows;\n  const nextCursor = hasMore\n    ? Buffer.from(JSON.stringify({ id: items[items.length - 1].id, createdAt: items[items.length - 1].created_at })).toString('base64')\n    : null;\n\n  res.json({ items, nextCursor, hasMore });\n});\n```",
    "why": "Cursor pagination uses an indexed WHERE clause instead of OFFSET, so performance is constant regardless of page depth. It also handles concurrent inserts correctly.",
    "gotchas": [
      "Cursor pagination cannot jump to arbitrary pages — it is only forward (and sometimes backward) navigation",
      "The cursor must encode all ORDER BY columns to handle ties correctly",
      "Encode cursors as base64 or encrypt them so clients cannot tamper with them",
      "If you need total count, cursor pagination requires a separate COUNT query which is expensive on large tables"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["cursor pagination", "offset pagination", "keyset pagination", "large datasets", "infinite scroll", "performance"],
    "severity": "moderate",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Token bucket rate limiting: algorithm and Redis implementation",
    "category": "pattern",
    "tags": ["rate-limiting", "token-bucket", "api", "abuse-prevention", "redis"],
    "problem": "An API endpoint is being hammered by a client, consuming all server resources and degrading service for other users.",
    "solution": "Implement token bucket rate limiting using Redis with atomic Lua execution:\n\n```javascript\nimport { createClient } from 'redis';\nconst redis = createClient();\n\nasync function tokenBucketAllow(key, { capacity = 10, refillRate = 1, refillIntervalMs = 1000 } = {}) {\n  const now = Date.now();\n  const bucketKey = `ratelimit:${key}`;\n\n  // Lua script executes atomically on the Redis server\n  const script = `\n    local tokens = tonumber(redis.call('hget', KEYS[1], 'tokens'))\n    local last = tonumber(redis.call('hget', KEYS[1], 'last'))\n    local now = tonumber(ARGV[1])\n    local capacity = tonumber(ARGV[2])\n    local refill_rate = tonumber(ARGV[3])\n    local interval = tonumber(ARGV[4])\n\n    if not tokens then\n      tokens = capacity\n      last = now\n    end\n\n    local elapsed = math.floor((now - last) / interval)\n    tokens = math.min(capacity, tokens + elapsed * refill_rate)\n    last = last + elapsed * interval\n\n    if tokens < 1 then\n      redis.call('hset', KEYS[1], 'tokens', tokens, 'last', last)\n      redis.call('expire', KEYS[1], 3600)\n      return 0\n    end\n\n    redis.call('hset', KEYS[1], 'tokens', tokens - 1, 'last', last)\n    redis.call('expire', KEYS[1], 3600)\n    return 1\n  `;\n\n  const allowed = await redis.sendCommand(['FCALL', script, '1', bucketKey, String(now), String(capacity), String(refillRate), String(refillIntervalMs)]);\n  return allowed === 1;\n}\n\n// Express middleware\napp.use('/api/', async (req, res, next) => {\n  const allowed = await tokenBucketAllow(req.ip, { capacity: 60, refillRate: 1, refillIntervalMs: 1000 });\n  if (!allowed) {\n    res.setHeader('Retry-After', '1');\n    return res.status(429).json({ error: 'Rate limit exceeded' });\n  }\n  next();\n});\n```",
    "why": "Using an atomic Lua script in Redis makes the check-and-decrement operation race-condition free. Token bucket allows bursting up to the capacity before throttling, which accommodates legitimate usage spikes.",
    "gotchas": [
      "Rate limit by user ID (authenticated) not just IP — IP-based limits are easily bypassed and can block shared IPs",
      "Add rate limit headers: X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset",
      "Return 429 (not 503) with a Retry-After header so well-behaved clients back off automatically",
      "Consider separate limits per tier (free vs paid) rather than one global limit"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [
      "429 Too Many Requests"
    ],
    "keywords": ["rate limiting", "token bucket", "Redis", "429", "Lua script", "burst", "throttling"],
    "severity": "major",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Health check endpoints: liveness vs readiness and what to include",
    "category": "pattern",
    "tags": ["health-check", "kubernetes", "api", "observability", "readiness"],
    "problem": "A single /health endpoint is used for both 'is the process alive' and 'is the app ready to serve traffic', causing Kubernetes to send traffic to starting apps or restart apps that are temporarily overloaded.",
    "solution": "Implement separate liveness and readiness endpoints:\n\n```javascript\n// Liveness: is the process alive? (Kubernetes restarts on failure)\n// Keep this SIMPLE — only fail if the process is genuinely stuck\napp.get('/health/live', (req, res) => {\n  res.status(200).json({ status: 'alive', pid: process.pid });\n});\n\n// Readiness: can the app serve traffic? (Load balancer removes from pool on failure)\n// Check all dependencies needed to serve a real request\napp.get('/health/ready', async (req, res) => {\n  const checks = {};\n  let ready = true;\n\n  try {\n    await db.raw('SELECT 1');\n    checks.database = 'ok';\n  } catch (err) {\n    checks.database = err.message;\n    ready = false;\n  }\n\n  if (app.locals.startingUp) {\n    checks.startup = 'in-progress';\n    ready = false;\n  }\n\n  res.status(ready ? 200 : 503).json({\n    ready,\n    checks,\n    version: process.env.APP_VERSION,\n  });\n});\n\n// Kubernetes deployment.yaml\n// livenessProbe:\n//   httpGet: { path: /health/live, port: 3000 }\n//   initialDelaySeconds: 30\n//   periodSeconds: 10\n// readinessProbe:\n//   httpGet: { path: /health/ready, port: 3000 }\n//   initialDelaySeconds: 5\n//   periodSeconds: 5\n```",
    "why": "A liveness probe that checks dependencies will restart pods unnecessarily when a dependency has a brief outage. A readiness probe removes the pod from the load balancer rotation instead.",
    "gotchas": [
      "Never put expensive operations in health check endpoints — they are called frequently",
      "Health check endpoints must not require authentication",
      "initialDelaySeconds must be long enough for the app to start and connect to the database",
      "A failing liveness probe causes a restart loop if the underlying problem is not fixed"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["health check", "liveness probe", "readiness probe", "kubernetes", "503", "startup probe"],
    "severity": "major",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Structured logging: JSON logs for machine-readable observability",
    "category": "pattern",
    "tags": ["logging", "structured-logging", "json", "observability", "pino"],
    "problem": "Text-based logs are difficult to search, filter, and aggregate in log management systems. Finding all errors for a specific user or request requires complex regex.",
    "solution": "Use structured JSON logging with a library like pino:\n\n```javascript\nimport pino from 'pino';\n\nconst logger = pino({\n  level: process.env.LOG_LEVEL || 'info',\n  // Pretty print in development\n  transport: process.env.NODE_ENV === 'development'\n    ? { target: 'pino-pretty' }\n    : undefined,\n  base: {\n    service: 'myapp',\n    version: process.env.APP_VERSION,\n    env: process.env.NODE_ENV,\n  },\n});\n\n// Use structured fields, not string interpolation\n// BAD:\nlogger.info(`User ${userId} created order ${orderId}`);\n\n// GOOD:\nlogger.info({ userId, orderId, amount }, 'Order created');\n\n// Output: {\"level\":\"info\",\"userId\":\"u_123\",\"orderId\":\"o_456\",\"amount\":1999,\"msg\":\"Order created\"}\n\n// Request logging middleware\napp.use((req, res, next) => {\n  const start = Date.now();\n  res.on('finish', () => {\n    logger.info({\n      method: req.method,\n      path: req.path,\n      status: res.statusCode,\n      durationMs: Date.now() - start,\n      correlationId: req.headers['x-correlation-id'],\n    }, 'HTTP request');\n  });\n  next();\n});\n```",
    "why": "JSON logs allow log aggregators (Datadog, CloudWatch, Loki) to index individual fields. You can query 'all errors where userId = X in the last hour' in seconds instead of grep-ing through files.",
    "gotchas": [
      "Never log sensitive data: passwords, tokens, PII, card numbers — even in debug mode",
      "Use log levels correctly: debug (verbose), info (normal operations), warn (potential problems), error (actionable failures)",
      "pino is 5x faster than winston and outputs proper JSON — use it for new projects",
      "In production, log to stdout and let the container/systemd collect it — don't write to files directly"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["structured logging", "JSON logs", "pino", "winston", "observability", "log aggregation", "correlation ID"],
    "severity": "moderate",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Correlation IDs: tracing requests across services and logs",
    "category": "pattern",
    "tags": ["correlation-id", "tracing", "distributed-systems", "logging", "debugging"],
    "problem": "A request touches 5 services and fails. Finding all related log entries across services requires searching by timestamp range and guessing which logs belong to the same request.",
    "solution": "Propagate a correlation ID through all service calls and log it with every entry:\n\n```javascript\nimport { AsyncLocalStorage } from 'node:async_hooks';\nimport { v4 as uuidv4 } from 'uuid';\n\n// Store correlation ID in async context (no thread-local in Node.js)\nconst correlationStorage = new AsyncLocalStorage();\n\n// Middleware: create or propagate correlation ID\napp.use((req, res, next) => {\n  const correlationId = req.headers['x-correlation-id'] || uuidv4();\n  res.setHeader('x-correlation-id', correlationId);\n  correlationStorage.run({ correlationId }, next);\n});\n\n// Helper to get current correlation ID\nconst getCorrelationId = () => correlationStorage.getStore()?.correlationId;\n\n// Logger automatically includes it\nconst logger = pino({\n  mixin: () => ({ correlationId: getCorrelationId() }),\n});\n\n// Forward to downstream services\nasync function callUserService(userId) {\n  return fetch(`http://user-service/users/${userId}`, {\n    headers: {\n      'x-correlation-id': getCorrelationId(),\n    },\n  });\n}\n```",
    "why": "AsyncLocalStorage provides Node.js equivalent of thread-local storage, propagating context through async call chains without passing it as a parameter to every function.",
    "gotchas": [
      "AsyncLocalStorage context is not automatically propagated across message queue consumers — re-extract the ID from the message payload",
      "Use a standard header name: x-correlation-id or x-request-id (pick one and use it everywhere)",
      "Correlation IDs should be set by the entry point (API gateway or first service) — not generated by each service",
      "When calling external services you don't control, still log the correlation ID on your side"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["correlation ID", "request ID", "distributed tracing", "AsyncLocalStorage", "x-correlation-id", "log context"],
    "severity": "moderate",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Cache invalidation strategies: TTL, event-driven, and cache-aside",
    "category": "pattern",
    "tags": ["cache", "invalidation", "redis", "cache-aside", "consistency"],
    "problem": "Cached data becomes stale after the underlying data changes, causing users to see outdated information. Or the cache is invalidated too aggressively, eliminating the performance benefit.",
    "solution": "Choose the right strategy for each use case:\n\n```javascript\n// 1. Cache-Aside (most common): check cache, miss -> load from DB, store in cache\nasync function getUser(userId) {\n  const cacheKey = `user:${userId}`;\n  const cached = await redis.get(cacheKey);\n  if (cached) return JSON.parse(cached);\n\n  const user = await db.query('SELECT * FROM users WHERE id = $1', [userId]);\n  await redis.setEx(cacheKey, 3600, JSON.stringify(user)); // TTL: 1 hour\n  return user;\n}\n\n// 2. Event-driven invalidation: invalidate on write\nasync function updateUser(userId, data) {\n  await db.query('UPDATE users SET ... WHERE id = $1', [userId]);\n  await redis.del(`user:${userId}`);  // Invalidate immediately\n}\n\n// 3. Write-through: update cache and DB together\nasync function updateUserWriteThrough(userId, data) {\n  await Promise.all([\n    db.query('UPDATE users SET ... WHERE id = $1', [userId]),\n    redis.setEx(`user:${userId}`, 3600, JSON.stringify({ id: userId, ...data })),\n  ]);\n}\n\n// 4. Stale-while-revalidate: return stale, refresh in background\nasync function getWithSWR(key, fetchFn, { ttl = 60, staleTtl = 300 } = {}) {\n  const cached = await redis.get(key);\n  if (cached) {\n    const { data, cachedAt } = JSON.parse(cached);\n    const age = (Date.now() - cachedAt) / 1000;\n    if (age > ttl) {\n      // Refresh in background, return stale data now\n      fetchFn().then(fresh =>\n        redis.setEx(key, staleTtl, JSON.stringify({ data: fresh, cachedAt: Date.now() }))\n      );\n    }\n    return data;\n  }\n  const data = await fetchFn();\n  await redis.setEx(key, staleTtl, JSON.stringify({ data, cachedAt: Date.now() }));\n  return data;\n}\n```",
    "why": "Cache-Aside is the safest pattern because the application controls what goes in the cache. Event-driven invalidation minimizes staleness for frequently updated data.",
    "gotchas": [
      "Cache stampede (thundering herd): when a popular key expires, many requests hit the DB simultaneously — use a lock or probabilistic early expiration",
      "Race condition: update DB then invalidate cache. If another request reads between update and invalidation, it will cache the old value — add a short TTL as safety net",
      "Never cache errors — a failed DB query should not be cached as empty result",
      "Namespace cache keys by version: v2:user:${id} makes cache busting easy during schema changes"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["cache invalidation", "cache-aside", "write-through", "stale-while-revalidate", "Redis TTL", "cache stampede"],
    "severity": "major",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Optimistic vs pessimistic locking: choosing the right concurrency strategy",
    "category": "principle",
    "tags": ["database", "locking", "concurrency", "transactions", "postgres"],
    "problem": "Two users simultaneously edit the same record. One update silently overwrites the other, causing lost writes with no error shown to either user.",
    "solution": "Choose locking strategy based on conflict probability:\n\n```sql\n-- PESSIMISTIC: Lock the row before reading (FOR UPDATE)\n-- Use when conflicts are expected (inventory, seats, funds)\nBEGIN;\nSELECT * FROM accounts WHERE id = $1 FOR UPDATE;  -- Blocks other transactions\nUPDATE accounts SET balance = balance - $2 WHERE id = $1;\nCOMMIT;\n```\n\n```javascript\n// OPTIMISTIC: Add a version column, fail on mismatch\n// Use when conflicts are rare (document editing, user profiles)\n\n// Schema: ALTER TABLE documents ADD COLUMN version INTEGER DEFAULT 1;\n\nasync function updateDocument(id, content, expectedVersion) {\n  const result = await db.query(\n    `UPDATE documents\n     SET content = $1, version = version + 1\n     WHERE id = $2 AND version = $3\n     RETURNING *`,\n    [content, id, expectedVersion]\n  );\n\n  if (result.rowCount === 0) {\n    throw new ConflictError('Document was modified by someone else. Please refresh and try again.');\n  }\n\n  return result.rows[0];\n}\n\n// Client always sends the version it read:\n// PUT /documents/:id { content: '...', version: 5 }\n// Returns 409 Conflict if version is stale\n```",
    "why": "Optimistic locking scales better (no database locks held during user think time). Pessimistic locking is simpler and necessary when you cannot tolerate any conflict (financial transactions).",
    "gotchas": [
      "Optimistic lock conflicts must be surfaced to the user — silent retries that overwrite are still lost updates",
      "FOR UPDATE with a long transaction blocks all other readers of that row on some isolation levels",
      "Use FOR UPDATE SKIP LOCKED for job queues — skip rows locked by other workers instead of waiting",
      "Deadlocks are possible with pessimistic locking — always acquire locks in the same order"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [
      "ERROR: could not serialize access due to concurrent update"
    ],
    "keywords": ["optimistic locking", "pessimistic locking", "version column", "FOR UPDATE", "lost update", "concurrency", "409 Conflict"],
    "severity": "major",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Eventual consistency: designing for it instead of fighting it",
    "category": "principle",
    "tags": ["eventual-consistency", "distributed-systems", "database", "design"],
    "problem": "A distributed system has nodes that replicate asynchronously. Users see stale data after writes, and code that assumes strong consistency produces bugs.",
    "solution": "Design your application to embrace eventual consistency:\n\n```javascript\n// 1. Read-your-writes: route reads to the primary after writes\nconst db = {\n  primary: createClient({ host: 'primary.db' }),\n  replica: createClient({ host: 'replica.db' }),\n};\n\nasync function createPost(userId, data) {\n  const post = await db.primary.query('INSERT INTO posts ...', [data]);\n  // Store token indicating this user has a recent write\n  await redis.setEx(`wrote:${userId}`, 60, '1');\n  return post;\n}\n\nasync function getPosts(userId) {\n  const hasRecentWrite = await redis.get(`wrote:${userId}`);\n  // Read from primary if user just wrote, otherwise use replica\n  const client = hasRecentWrite ? db.primary : db.replica;\n  return client.query('SELECT * FROM posts WHERE user_id = $1', [userId]);\n}\n\n// 2. Optimistic UI: show the expected state immediately\n// Client renders the new comment before server confirms\n// Rollback on error with user notification\n\n// 3. For counts and aggregates: accept slight staleness\n// Exact counts: always read from primary\n// Display counts: read from replica or cache\n```",
    "why": "Read replicas improve read throughput but have replication lag. Knowing which queries need strong consistency (payment totals) vs. can tolerate staleness (view counts) lets you use replicas safely.",
    "gotchas": [
      "Never use a read replica for anything that feeds into a write decision (check balance before debit)",
      "Replication lag can be seconds to minutes under load — do not assume it is milliseconds",
      "session_id is a good routing key for sticky sessions to the same replica if you cannot afford primary reads",
      "Cassandra and DynamoDB with eventual consistency need idempotent writes for safe retries"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["eventual consistency", "replication lag", "read replica", "primary", "read-your-writes", "distributed systems", "stale data"],
    "severity": "major",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Graceful degradation: returning partial results when dependencies fail",
    "category": "pattern",
    "tags": ["graceful-degradation", "resilience", "availability", "fault-tolerance"],
    "problem": "A recommendation engine or non-critical service fails, causing the entire page or API response to return an error even though the core functionality still works.",
    "solution": "Use Promise.allSettled and fallbacks for non-critical data:\n\n```javascript\nasync function getProductPage(productId, userId) {\n  // Parallel fetch — don't let one failure block others\n  const [\n    productResult,\n    reviewsResult,\n    recommendationsResult,\n    inventoryResult\n  ] = await Promise.allSettled([\n    productService.get(productId),              // Critical\n    reviewService.getForProduct(productId),     // Nice to have\n    recommendationEngine.get(userId, productId), // Nice to have\n    inventoryService.getCount(productId),        // Important\n  ]);\n\n  // Critical: fail the whole request if product fetch fails\n  if (productResult.status === 'rejected') {\n    throw productResult.reason;\n  }\n\n  return {\n    product: productResult.value,\n    // Fallback to empty array if reviews fail — page still loads\n    reviews: reviewsResult.status === 'fulfilled' ? reviewsResult.value : [],\n    // Fallback to null — frontend shows 'recommendations unavailable'\n    recommendations: recommendationsResult.status === 'fulfilled' ? recommendationsResult.value : null,\n    // Fallback to 'unknown' — show 'check availability' button\n    inventory: inventoryResult.status === 'fulfilled' ? inventoryResult.value : { status: 'unknown' },\n    // Log all failures for monitoring\n    _errors: [\n      reviewsResult.status === 'rejected' && { service: 'reviews', error: reviewsResult.reason?.message },\n      recommendationsResult.status === 'rejected' && { service: 'recommendations', error: recommendationsResult.reason?.message },\n    ].filter(Boolean),\n  };\n}\n```",
    "why": "Promise.allSettled does not short-circuit on rejection. Each result has a status field, so you can handle critical vs non-critical failures differently.",
    "gotchas": [
      "Promise.all is wrong here — one rejection cancels all results. Use Promise.allSettled",
      "Log degradation events — consistent failures reveal which service needs attention",
      "Set timeouts on each downstream call — a slow service is as bad as a failed one",
      "The frontend must handle null/empty fallback values gracefully — coordinate with client teams"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["graceful degradation", "Promise.allSettled", "partial results", "fallback", "resilience", "fault tolerance", "non-critical service"],
    "severity": "major",
    "context": null,
    "code_snippets": [],
    "version_info": null
  },
  {
    "title": "Saga pattern: managing distributed transactions across services",
    "category": "pattern",
    "tags": ["saga", "distributed-systems", "transactions", "compensation", "microservices"],
    "problem": "A workflow touches multiple services (create order, reserve inventory, charge payment, send email). If any step fails halfway through, the system is left in an inconsistent state with no built-in rollback.",
    "solution": "Implement a saga with compensating transactions for each step:\n\n```javascript\nclass OrderSaga {\n  async execute(orderData) {\n    const sagaId = uuidv7();\n    const steps = [];\n\n    try {\n      // Step 1: Create order (draft state)\n      const order = await orderService.createDraft(orderData);\n      steps.push({ name: 'order', id: order.id });\n\n      // Step 2: Reserve inventory\n      const reservation = await inventoryService.reserve(order.items);\n      steps.push({ name: 'inventory', id: reservation.id });\n\n      // Step 3: Charge payment\n      const charge = await paymentService.charge(order.total, order.userId);\n      steps.push({ name: 'payment', id: charge.id });\n\n      // Step 4: Confirm order (final state)\n      await orderService.confirm(order.id);\n\n      // Step 5: Send confirmation email (non-critical — don't rollback on failure)\n      emailService.send(order).catch(err =>\n        logger.error({ err, sagaId }, 'Email failed')\n      );\n\n      return order;\n    } catch (err) {\n      logger.error({ err, sagaId, steps }, 'Saga failed, running compensations');\n      await this.compensate(steps);\n      throw new SagaError('Order processing failed', { cause: err });\n    }\n  }\n\n  async compensate(steps) {\n    // Compensate in reverse order\n    for (const step of steps.reverse()) {\n      try {\n        if (step.name === 'payment') await paymentService.refund(step.id);\n        if (step.name === 'inventory') await inventoryService.release(step.id);\n        if (step.name === 'order') await orderService.cancel(step.id);\n      } catch (err) {\n        // Log but continue compensating other steps\n        logger.error({ err, step }, 'Compensation step failed — manual intervention needed');\n      }\n    }\n  }\n}\n```",
    "why": "Distributed transactions (2PC) require all services to hold locks simultaneously, which is impractical across service boundaries. Sagas use compensating transactions to undo completed steps when a later step fails.",
    "gotchas": [
      "Compensating transactions must be idempotent — the compensation step might be called multiple times if the saga crashes and restarts",
      "Compensation can also fail — log failures to a dead letter queue for manual resolution",
      "The saga must be persisted (in a database) so it can be resumed after a crash — in-memory sagas are lost on restart",
      "Saga visibility: users see intermediate states (order created but not confirmed) — design the UI to communicate this"
    ],
    "language": "javascript",
    "framework": null,
    "environment": [],
    "error_messages": [],
    "keywords": ["saga pattern", "distributed transaction", "compensating transaction", "rollback", "microservices", "eventual consistency", "orchestration"],
    "severity": "major",
    "context": null,
    "code_snippets": [],
    "version_info": null
  }
]
